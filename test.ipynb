{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base.registry import RUNNER\n",
    "import torch.nn as nn\n",
    "\n",
    "@RUNNER.register_module()\n",
    "class Runner(nn.Module):\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        print(self.a, self.b)\n",
    "        return self.a + self.b\n",
    "    \n",
    "runner = RUNNER.build(dict(type='Runner', a=1, b=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 480, 320])\n",
      "torch.Size([4, 480, 320])\n"
     ]
    }
   ],
   "source": [
    "from base.registry import MY_DATASETS\n",
    "import os.path as osp\n",
    "root = osp.join('data', 'sonar')\n",
    "dataset = MY_DATASETS.build(dict(type=\"WaterTankDataset\", root=root))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "for output in dataloader:\n",
    "    print(output.get('img').shape)\n",
    "    print(output.get('mask').shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'OptimWrapper', 'optimizer': {'type': 'SGD', 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005}, 'clip_grad': None}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m optim_wrapper_ \u001b[38;5;241m=\u001b[39m build_optim_wrapper(model, copy\u001b[38;5;241m.\u001b[39mdeepcopy(optim_wrapper))\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(optim_wrapper)\n\u001b[1;32m---> 30\u001b[0m \u001b[43mRunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\GitHubProject\\semantic-segmentation-code\\tools\\runner.py:59\u001b[0m, in \u001b[0;36mRunner._build_optimizer\u001b[1;34m(self, model, optim_wrapper)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_optimizer\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m     57\u001b[0m                      model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m     58\u001b[0m                      optim_wrapper: Optional[Union[Optimizer, OptimWrapper, Dict]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_optim_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_wrapper\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Deeplearning\\Anaconda\\envs\\sonarseg\\lib\\site-packages\\mmengine\\optim\\optimizer\\builder.py:195\u001b[0m, in \u001b[0;36mbuild_optim_wrapper\u001b[1;34m(model, cfg)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build function of OptimWrapper.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03mIf ``constructor`` is set in the ``cfg``, this method will build an\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m    OptimWrapper: The built optimizer wrapper.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    194\u001b[0m optim_wrapper_cfg \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(cfg)\n\u001b[1;32m--> 195\u001b[0m constructor_type \u001b[38;5;241m=\u001b[39m \u001b[43moptim_wrapper_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstructor\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    196\u001b[0m                                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDefaultOptimWrapperConstructor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    197\u001b[0m paramwise_cfg \u001b[38;5;241m=\u001b[39m optim_wrapper_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparamwise_cfg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Since the current generation of NPU(Ascend 910) only supports\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# mixed precision training, here we turn on mixed precision\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# to make the training normal\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from mmengine.optim import (OptimWrapper, OptimWrapperDict, _ParamScheduler,\n",
    "                            build_optim_wrapper)\n",
    "# from mmengine.registry import OPTIM_WRAPPERS\n",
    "from tools.runner import Runner\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 3, 3)\n",
    "        self.bn = nn.BatchNorm2d(3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "\n",
    "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "optim_wrapper = dict(type='OptimWrapper', optimizer=optimizer, clip_grad=None)\n",
    "\n",
    "optim_wrapper_ = build_optim_wrapper(model, copy.deepcopy(optim_wrapper))\n",
    "print(optim_wrapper)\n",
    "Runner._build_optimizer(model, copy.deepcopy(optim_wrapper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "optim_wrapper = dict(type='OptimWrapper', optimizer=optimizer, clip_grad=None)\n",
    "Runner._build_optimizer(model, copy.deepcopy(optim_wrapper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sonarseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
